{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ea7e302-1dac-4088-8d59-7b3b2ddd55fe",
   "metadata": {},
   "source": [
    "## Transformer Multimodal (75 Samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "646a5918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import make_scorer, accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8623e9",
   "metadata": {},
   "source": [
    "## Extracting data from .s1p files and .mat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a2600c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper Functions ###\n",
    "\n",
    "def extract_s11_from_s1p(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Skip header lines that start with ! or #\n",
    "            if not line.startswith(('!', '#')):\n",
    "                columns = line.split()\n",
    "                # Collect only S11_Real (second column)\n",
    "                data.append(float(columns[1]))\n",
    "    return data\n",
    "\n",
    "# Function to parse Lg, Vds, and Vgs from filenames\n",
    "def parse_filename_parameters(filename):\n",
    "    # Initialize default values\n",
    "    Lg = Vds = Vgs = 'NA'\n",
    "    \n",
    "    # Use regex to search for Lg, Vds, and Vgs patterns in the filename\n",
    "    lg_match = re.search(r'Lg(\\d+)p(\\d+)', filename)\n",
    "    vds_match = re.search(r'Vds(\\d+)', filename)\n",
    "    vgs_match = re.search(r'Vgs(\\d+)', filename)\n",
    "\n",
    "    # Process the Lg match with \"p\" as decimal point\n",
    "    if lg_match:\n",
    "        Lg = float(f\"{lg_match.group(1)}.{lg_match.group(2)}\")\n",
    "    if vds_match:\n",
    "        Vds = int(vds_match.group(1))\n",
    "    if vgs_match:\n",
    "        Vgs = int(vgs_match.group(1))\n",
    "    \n",
    "    # If 'Opend' is in the filename, set Vds to 10000\n",
    "    if 'opend' in filename:\n",
    "        Vds = 10000\n",
    "    \n",
    "    return Lg, Vds, Vgs\n",
    "\n",
    "# Function to find repeating pattern\n",
    "def find_repeating_pattern(waveform, min_period=1000, num_periods=5):\n",
    "    # Calculate autocorrelation\n",
    "    autocorr = np.correlate(waveform, waveform, mode='full')\n",
    "    autocorr = autocorr[autocorr.size // 2:]  # Keep only the second half\n",
    "\n",
    "    # Find the first peak after lag=0\n",
    "    differences = np.diff(autocorr)  # Differences between consecutive points\n",
    "    peaks = np.where((differences[:-1] > 0) & (differences[1:] < 0))[0] + 1  # Peak detection\n",
    "    \n",
    "    # Find the period\n",
    "    if len(peaks) > 0:\n",
    "        period = peaks[0]  # The first peak indicates the repeating period\n",
    "        if period < min_period:\n",
    "            period = min_period  # Enforce minimum period\n",
    "    else:\n",
    "        period = min_period  # Default to minimum period if no peaks are found\n",
    "\n",
    "    # Extract multiple periods of the waveform\n",
    "    end_index = period * num_periods\n",
    "    repeating_pattern = waveform[:end_index]\n",
    "    \n",
    "    return repeating_pattern, period\n",
    "\n",
    "def filter_dataset_by_columns(main_dataset, subset_dataset, matching_columns):\n",
    "    \"\"\"\n",
    "    Filters rows in the main dataset where the values in matching columns \n",
    "    match those in the subset dataset.\n",
    "\n",
    "    Parameters:\n",
    "        main_dataset (pd.DataFrame): The primary dataset to filter.\n",
    "        subset_dataset (pd.DataFrame): The subset with matching criteria.\n",
    "        matching_columns (list): List of column names to match on.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A filtered dataset with matching rows.\n",
    "    \"\"\"\n",
    "    # Filter rows in the main dataset where matching column values are in the subset dataset\n",
    "    filtered_dataset = main_dataset[\n",
    "        main_dataset[matching_columns].apply(tuple, axis=1).isin(\n",
    "            subset_dataset[matching_columns].apply(tuple, axis=1)\n",
    "        )\n",
    "    ]\n",
    "    return filtered_dataset\n",
    "\n",
    "def smooth_dataframe_columns(df, group_size, fixed_start_cols, fixed_end_cols):\n",
    "    \n",
    "    if group_size <= 0:\n",
    "        raise ValueError(\"Group size must be greater than 0.\")\n",
    "    \n",
    "    # Separate fixed columns\n",
    "    fixed_start = df.iloc[:, :fixed_start_cols]\n",
    "    fixed_end = df.iloc[:, -fixed_end_cols:]\n",
    "    \n",
    "    # Columns to smooth (excluding fixed columns)\n",
    "    smooth_cols = df.iloc[:, fixed_start_cols:-fixed_end_cols]\n",
    "\n",
    "    # Smooth by averaging every `group_size` columns\n",
    "    smoothed_data = []\n",
    "    for i in range(0, smooth_cols.shape[1], group_size):\n",
    "        chunk = smooth_cols.iloc[:, i:i+group_size]\n",
    "        smoothed_data.append(chunk.mean(axis=1))\n",
    "\n",
    "    # Handle remaining columns if not a perfect multiple of group_size\n",
    "    if smooth_cols.shape[1] % group_size != 0:\n",
    "        remaining_cols = smooth_cols.iloc[:, -(smooth_cols.shape[1] % group_size):]\n",
    "        smoothed_data.append(remaining_cols.mean(axis=1))\n",
    "\n",
    "    # Combine fixed columns with smoothed data\n",
    "    smoothed_df = pd.concat([fixed_start] + smoothed_data + [fixed_end], axis=1)\n",
    "    return smoothed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92369409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_sync_dataset(S1P_file_path, TDR_file_path):\n",
    "    \n",
    "    s11_data = {}\n",
    "    frequency_data = None\n",
    "    \n",
    "    # Loop over all .s1p files in the directory\n",
    "    for filename in os.listdir(S1P_file_path):\n",
    "        if filename.endswith('.s1p'):\n",
    "            file_path = os.path.join(S1P_file_path, filename)\n",
    "            s11_values = extract_s11_from_s1p(file_path)\n",
    "            \n",
    "            # Use the first file's frequency values as a reference\n",
    "            if frequency_data is None:\n",
    "                with open(file_path, 'r') as file:\n",
    "                    frequency_data = [float(line.split()[0]) for line in file if not line.startswith(('!', '#'))]\n",
    "            \n",
    "            s11_data[filename] = s11_values\n",
    "            \n",
    "    s11_dataset = pd.DataFrame(s11_data).T\n",
    "    s11_dataset.columns = [f'Frequency_{i}' for i in range(len(s11_dataset.columns))]  # Set column names dynamically\n",
    "    s11_dataset.insert(0, 'File', s11_dataset.index) \n",
    "    \n",
    "    Duty_list = []\n",
    "\n",
    "    #for index, row in s11_dataframe.iterrows():\n",
    "    for i in s11_dataset['File']:\n",
    "        if 'dut1' in i:\n",
    "            Duty_list.append(1)\n",
    "        elif 'dut5' in i:\n",
    "            Duty_list.append(0)\n",
    "        else:\n",
    "            Duty_list.append('NA')\n",
    "    \n",
    "    s11_dataset = s11_dataset.drop(columns=['Frequency_0'], errors='ignore')  # Ignore error if column does not exist\n",
    "    \n",
    "    s11_dataset[['Lg', 'Vds', 'Vgs']] = s11_dataset['File'].apply(lambda x: pd.Series(parse_filename_parameters(x)))\n",
    "    s11_dataset = s11_dataset[['Lg', 'Vds', 'Vgs'] + [col for col in s11_dataset.columns if col.startswith('Frequency')]]\n",
    "    s11_dataset['Duty'] = Duty_list\n",
    "    \n",
    "    # Initialize a dictionary to store the loaded data\n",
    "    mat_data = {}\n",
    "\n",
    "    # Loop through the files in the folder\n",
    "    for file_name in os.listdir(TDR_file_path):\n",
    "        if file_name.endswith('.mat'):  # Check if the file is a .mat file\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(TDR_file_path, file_name)\n",
    "            # Load the .mat file and store it in the dictionary\n",
    "            mat_data[file_name] = loadmat(file_path)\n",
    "\n",
    "    # Access the loaded data as needed\n",
    "    tdr_train = mat_data.get('TDR_train.mat')\n",
    "    tdr_test = mat_data.get('TDR_test.mat')\n",
    "    tdr_val = mat_data.get('TDR_val.mat')\n",
    "    \n",
    "    # Extract and convert the datasets to DataFrames\n",
    "    train_data = pd.DataFrame(tdr_train[\"dataTDRtrain\"])\n",
    "    test_data = pd.DataFrame(tdr_test[\"dataTDRtest\"])\n",
    "    val_data = pd.DataFrame(tdr_val[\"dataTDRval\"])\n",
    "    \n",
    "    num_columns = train_data.shape[1]\n",
    "    column_names = [f\"t_{i+1}\" for i in range(num_columns)]\n",
    "\n",
    "    # Assign these column names to the DataFrame\n",
    "    train_data.columns = column_names\n",
    "    test_data.columns = column_names\n",
    "    val_data.columns = column_names\n",
    "    \n",
    "    # Specify the path to your Excel file\n",
    "    excel_file_path = r'C:\\Master_thesis\\creating_dataset\\TDR\\key_identifiers.xlsx'\n",
    "\n",
    "    # Load each sheet into a separate DataFrame\n",
    "    identifiers_train = pd.read_excel(excel_file_path, sheet_name='train', header=1)\n",
    "    identifiers_test = pd.read_excel(excel_file_path, sheet_name='test', header=1)\n",
    "    identifiers_val = pd.read_excel(excel_file_path, sheet_name='val', header=1)\n",
    "\n",
    "    train_dataset = pd.concat([identifiers_train, train_data], axis=1)\n",
    "    test_dataset = pd.concat([identifiers_test, test_data], axis=1)\n",
    "    val_dataset = pd.concat([identifiers_val, val_data], axis=1)\n",
    "\n",
    "    # The column to move to the last position (for example, column 'B')\n",
    "    col_to_move = 'Duty'\n",
    "\n",
    "    # Function to move a column to the last position in a DataFrame\n",
    "    def move_column_to_last(df, col_to_move):\n",
    "        cols = [col for col in df.columns if col != col_to_move]\n",
    "        df = df[cols + [col_to_move]]\n",
    "        return df\n",
    "\n",
    "    # Apply the function to each dataset\n",
    "    train_dataset = move_column_to_last(train_dataset, col_to_move)\n",
    "    test_dataset = move_column_to_last(test_dataset, col_to_move)\n",
    "    val_dataset = move_column_to_last(val_dataset, col_to_move)\n",
    "\n",
    "    TDR_dataset = pd.concat([train_dataset, test_dataset, val_dataset], axis=0, ignore_index=True)\n",
    "\n",
    "    TDR_dataset['Duty'] = TDR_dataset['Duty'].replace({1: 1, 5: 0})\n",
    "    print()\n",
    "    # Columns for comparison\n",
    "    common_columns = ['Lg', 'Vds', 'Vgs', 'Duty']\n",
    "\n",
    "    # Identify common samples\n",
    "    common_samples = pd.merge(s11_dataset[common_columns], TDR_dataset[common_columns], on=common_columns)\n",
    "\n",
    "    # Subset 1: Rows in df1 not in common samples\n",
    "    #unsync_s11_dataset = s11_dataset[~s11_dataset[common_columns].apply(tuple, axis=1).isin(common_samples.apply(tuple, axis=1))]\n",
    "    \n",
    "    # Subset 2: Common samples from df1 with all df1 columns\n",
    "    sync_s11_dataset = s11_dataset[s11_dataset[common_columns].apply(tuple, axis=1).isin(common_samples.apply(tuple, axis=1))]\n",
    "    #print(sync_s11_dataset.shape)\n",
    "    # Subset 3: Common samples from df2 with all df2 columns\n",
    "    sync_TDR_dataset = TDR_dataset[TDR_dataset[common_columns].apply(tuple, axis=1).isin(common_samples.apply(tuple, axis=1))]\n",
    "\n",
    "    # Subset 4: Rows in df2 not in common samples\n",
    "    unsync_TDR_dataset = TDR_dataset[~TDR_dataset[common_columns].apply(tuple, axis=1).isin(common_samples.apply(tuple, axis=1))]\n",
    "\n",
    "    sync_TDR_dataset = smooth_dataframe_columns(sync_TDR_dataset, 63, 3, 1)\n",
    "    unsync_TDR_dataset = smooth_dataframe_columns(unsync_TDR_dataset, 63, 3, 1)\n",
    "    TDR_dataset = smooth_dataframe_columns(TDR_dataset, 63, 3, 1)\n",
    "    \n",
    "    # Create a DataFrame filled with zeros\n",
    "    unsync_s11_dataset = pd.DataFrame(np.zeros((45, 1004)))\n",
    "    \n",
    "    # Rename only the last column\n",
    "    col_names = [f\"col_{i}\" for i in range(unsync_s11_dataset.shape[1])]  # Generate default column names\n",
    "    col_names[-1] = \"Duty\" \n",
    "    col_names[0] = \"Lg\" \n",
    "    col_names[1] = \"Vds\" \n",
    "    col_names[2] = \"Vgs\"\n",
    "    unsync_s11_dataset.columns = col_names\n",
    "    \n",
    "    unsync_s11_dataset['Duty'] = unsync_TDR_dataset['Duty'].values\n",
    "    unsync_s11_dataset['Lg'] = unsync_TDR_dataset['Lg'].values\n",
    "    unsync_s11_dataset['Vds'] = unsync_TDR_dataset['Vds'].values\n",
    "    unsync_s11_dataset['Vgs'] = unsync_TDR_dataset['Vgs'].values\n",
    "    \n",
    "    \n",
    "    for i in range (3, len(unsync_s11_dataset.columns)-1):\n",
    "        col_name = f'Frequency_{i-2}'\n",
    "        unsync_s11_dataset.columns.values[i] = col_name\n",
    "\n",
    "    s11_dataset = pd.concat([sync_s11_dataset, unsync_s11_dataset], ignore_index=True)\n",
    "    \n",
    "    return s11_dataset, TDR_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "334c156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1P_file_path = r'C:\\Master_thesis\\creating_dataset\\Dataset\\S11'\n",
    "TDR_file_path = r'C:\\Master_thesis\\creating_dataset\\TDR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "810e84fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "s11_dataset, TDR_dataset = creating_sync_dataset(S1P_file_path, TDR_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa6f324c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75, 1004), (75, 1006))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s11_dataset.shape, TDR_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab3a27a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_Scaling_Sync(sync_s11_dataset, sync_TDR_dataset, scaling_type):\n",
    "    \n",
    "    train_shape = int((sync_s11_dataset.shape[0])*0.6)\n",
    "    test_shape = int((sync_s11_dataset.shape[0])*0.2)\n",
    "    val_shape = int((sync_s11_dataset.shape[0])*0.2)\n",
    "\n",
    "    sync_s11_dataset = sync_s11_dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Step 1: Split into train and temp_data (test + val)\n",
    "    s11_train, temp_data = train_test_split(sync_s11_dataset, train_size=train_shape, random_state=42, stratify=sync_s11_dataset[\"Duty\"])\n",
    "\n",
    "    # Step 2: Split temp_data into test and val (ensuring balance in \"Duty\")\n",
    "    s11_test, s11_val = train_test_split(temp_data, train_size=test_shape, random_state=42, stratify=temp_data[\"Duty\"])\n",
    "\n",
    "    # Columns for matching\n",
    "    matching_column = ['Lg', 'Vds', 'Vgs', 'Duty']\n",
    "\n",
    "    TDR_train = filter_dataset_by_columns(sync_TDR_dataset, s11_train, matching_column)\n",
    "    TDR_test = filter_dataset_by_columns(sync_TDR_dataset, s11_test, matching_column)\n",
    "    TDR_val = filter_dataset_by_columns(sync_TDR_dataset, s11_val, matching_column)\n",
    "    \n",
    "    # Perform an inner merge to keep only rows where both A and B match\n",
    "    merged_train = pd.merge(s11_train, TDR_train, on=['Lg', 'Vds', 'Vgs', 'Duty'], how='inner')\n",
    "    merged_test = pd.merge(s11_test, TDR_test, on=['Lg', 'Vds', 'Vgs', 'Duty'], how='inner')\n",
    "    merged_val = pd.merge(s11_val, TDR_val, on=['Lg', 'Vds', 'Vgs', 'Duty'], how='inner')\n",
    "    \n",
    "    # Separate the DataFrames back\n",
    "    s11_train = merged_train[s11_train.columns]\n",
    "    TDR_train = merged_train[TDR_train.columns]\n",
    "    \n",
    "    s11_test = merged_test[s11_test.columns]\n",
    "    TDR_test = merged_test[TDR_test.columns]\n",
    "    \n",
    "    s11_val = merged_val[s11_val.columns]\n",
    "    TDR_val = merged_val[TDR_val.columns]\n",
    "       \n",
    "    \n",
    "    #TDR_train = smooth_dataframe_columns(TDR_train, 63, 3, 1)\n",
    "    #TDR_test = smooth_dataframe_columns(TDR_test, 63, 3, 1)\n",
    "    #TDR_val = smooth_dataframe_columns(TDR_val, 63, 3, 1)\n",
    "    \n",
    "    X_s11_train = s11_train.iloc[:, 0:-1].values\n",
    "    y_s11_train = s11_train['Duty'].values\n",
    "\n",
    "    X_s11_test = s11_test.iloc[:, 0:-1].values\n",
    "    y_s11_test = s11_test['Duty'].values\n",
    "\n",
    "    X_s11_val = s11_val.iloc[:, 0:-1].values\n",
    "    y_s11_val = s11_val['Duty'].values\n",
    "\n",
    "    X_TDR_train = TDR_train.iloc[:, 0:-1].values\n",
    "    y_TDR_train = TDR_train['Duty'].values\n",
    "\n",
    "    X_TDR_test = TDR_test.iloc[:, 0:-1].values\n",
    "    y_TDR_test = TDR_test['Duty'].values\n",
    "\n",
    "    X_TDR_val = TDR_val.iloc[:, 0:-1].values\n",
    "    y_TDR_val = TDR_val['Duty'].values\n",
    "    \n",
    "    # Mapping of scaling types to scaler objects\n",
    "    scalers = {\n",
    "        'standard': StandardScaler(),\n",
    "        'minmax': MinMaxScaler(),\n",
    "        'robust': RobustScaler(),\n",
    "        'maxabs': MaxAbsScaler()\n",
    "    }\n",
    "\n",
    "    # Check if the scaling_type is valid\n",
    "    if scaling_type not in scalers:\n",
    "        raise ValueError(f\"Invalid scaling_type. Choose from {list(scalers.keys())}.\")\n",
    "    \n",
    "    # Select the appropriate scaler\n",
    "    scaler = scalers[scaling_type] \n",
    "    \n",
    "    X_s11_train_scaled = scaler.fit_transform(X_s11_train)\n",
    "    X_s11_test_scaled = scaler.transform(X_s11_test)\n",
    "    X_s11_val_scaled = scaler.transform(X_s11_val)\n",
    "        \n",
    "    X_TDR_train_scaled = scaler.fit_transform(X_TDR_train)\n",
    "    X_TDR_test_scaled = scaler.transform(X_TDR_test)\n",
    "    X_TDR_val_scaled = scaler.transform(X_TDR_val)\n",
    "    \n",
    "    # Convert data to PyTorch tensors\n",
    "    X_s11_train_scaled = torch.tensor(X_s11_train_scaled, dtype=torch.float32)\n",
    "    y_s11_train = torch.tensor(y_s11_train, dtype=torch.long)\n",
    "    X_s11_test_scaled = torch.tensor(X_s11_test_scaled, dtype=torch.float32)\n",
    "    y_s11_test = torch.tensor(y_s11_test, dtype=torch.long)\n",
    "    X_s11_val_scaled = torch.tensor(X_s11_val_scaled, dtype=torch.float32)\n",
    "    y_s11_val = torch.tensor(y_s11_val, dtype=torch.long)\n",
    "\n",
    "    # Convert data and labels to TensorDatasets and create DataLoaders\n",
    "    s11_train_dataset = TensorDataset(X_s11_train_scaled, y_s11_train.long())\n",
    "    s11_val_dataset = TensorDataset(X_s11_val_scaled, y_s11_val.long())\n",
    "    s11_test_dataset = TensorDataset(X_s11_test_scaled, y_s11_test.long())\n",
    "\n",
    "    s11_train_loader = torch.utils.data.DataLoader(s11_train_dataset, batch_size=4, shuffle=True)\n",
    "    s11_test_loader = torch.utils.data.DataLoader(s11_test_dataset, batch_size=4)\n",
    "    s11_val_loader = torch.utils.data.DataLoader(s11_val_dataset, batch_size=4)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_TDR_train_scaled = torch.tensor(X_TDR_train_scaled, dtype=torch.float32)\n",
    "    y_TDR_train = torch.tensor(y_TDR_train, dtype=torch.long)\n",
    "    X_TDR_test_scaled = torch.tensor(X_TDR_test_scaled, dtype=torch.float32)\n",
    "    y_TDR_test = torch.tensor(y_TDR_test, dtype=torch.long)\n",
    "    X_TDR_val_scaled = torch.tensor(X_TDR_val_scaled, dtype=torch.float32)\n",
    "    y_TDR_val = torch.tensor(y_TDR_val, dtype=torch.long)\n",
    "\n",
    "    # Convert data and labels to TensorDatasets and create DataLoaders\n",
    "    TDR_train_dataset = TensorDataset(X_TDR_train_scaled, y_TDR_train.long())\n",
    "    TDR_val_dataset = TensorDataset(X_TDR_val_scaled, y_TDR_val.long())\n",
    "    TDR_test_dataset = TensorDataset(X_TDR_test_scaled, y_TDR_test.long())\n",
    "\n",
    "    TDR_train_loader = torch.utils.data.DataLoader(TDR_train_dataset, batch_size=4, shuffle=True)\n",
    "    TDR_test_loader = torch.utils.data.DataLoader(TDR_test_dataset, batch_size=4)\n",
    "    TDR_val_loader = torch.utils.data.DataLoader(TDR_val_dataset, batch_size=4) \n",
    "    \n",
    "    return s11_train_loader, s11_test_loader, s11_val_loader, TDR_train_loader, TDR_test_loader, TDR_val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d35f33",
   "metadata": {},
   "source": [
    "## Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6319c6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Model for Duty Classification\n",
    "\n",
    "class DutyClassifier(nn.Module):\n",
    "    def __init__(self, seq_len1, seq_len2, input_dim, num_classes, d_model=128, nhead=8, num_layers=1):\n",
    "        super(DutyClassifier, self).__init__()\n",
    "        \n",
    "        # Separate embedding layers to map input dimensions to d_model\n",
    "        self.embedding1 = nn.Linear(input_dim, d_model)\n",
    "        self.embedding2 = nn.Linear(input_dim, d_model)\n",
    "        \n",
    "        # Separate transformer encoders for each input\n",
    "        encoder_layer1 = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
    "        encoder_layer2 = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
    "        \n",
    "        self.transformer_encoder1 = nn.TransformerEncoder(encoder_layer1, num_layers=num_layers)\n",
    "        self.transformer_encoder2 = nn.TransformerEncoder(encoder_layer2, num_layers=num_layers)\n",
    "        \n",
    "        # Classification layer\n",
    "        # The total dimension is (seq_len1 + seq_len2) * d_model after concatenation\n",
    "\n",
    "        self.classifier = nn.Linear(d_model * (seq_len1 + seq_len2), num_classes)\n",
    "     \n",
    "    def forward(self, x1, x2):\n",
    "        # Project each dataset to the common feature dimension (d_model)\n",
    "        x1 = self.embedding1(x1)  # Shape: [batch_size, seq_len1, d_model]\n",
    "        x2 = self.embedding2(x2)  # Shape: [batch_size, seq_len2, d_model]\n",
    "\n",
    "        # Transform the sequence for each dataset\n",
    "        x1 = x1.permute(1, 0, 2)  # Shape: [seq_len1, batch_size, d_model]\n",
    "        x1 = self.transformer_encoder1(x1)\n",
    "        x1 = x1.permute(1, 0, 2)  # Back to [batch_size, seq_len1, d_model]\n",
    "\n",
    "        x2 = x2.permute(1, 0, 2)  # Shape: [seq_len2, batch_size, d_model]\n",
    "        x2 = self.transformer_encoder2(x2)\n",
    "        x2 = x2.permute(1, 0, 2)  # Back to [batch_size, seq_len2, d_model]\n",
    "\n",
    "        # Concatenate along the sequence length dimension\n",
    "        x = torch.cat((x1, x2), dim=1)  # Shape: [batch_size, seq_len1 + seq_len2, d_model]\n",
    "\n",
    "        # Flatten for classification\n",
    "        x = x.flatten(start_dim=1)  # Shape: [batch_size, (seq_len1 + seq_len2) * d_model]\n",
    "        out = self.classifier(x)  # Shape: [batch_size, num_classes]\n",
    "\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceb240e",
   "metadata": {},
   "source": [
    "## Training and testing of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52c3dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, num_epochs, patience):\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        train_targets, train_preds = [], []\n",
    "        \n",
    "        # Iterate over both loaders simultaneously (synchronized)\n",
    "        for (s11_train_data, train_labels), (tdr_train_data, _) in zip(s11_train_loader, TDR_train_loader):\n",
    "            # Move inputs and labels to the appropriate device\n",
    "            s11_train_data = s11_train_data.to(device)\n",
    "            tdr_train_data = tdr_train_data.to(device)\n",
    "            train_labels = train_labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(s11_train_data.unsqueeze(-1), tdr_train_data.unsqueeze(-1))\n",
    "            loss = criterion(outputs, train_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            train_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "            train_targets.extend(train_labels.cpu().numpy())\n",
    "                \n",
    "        train_accuracy = accuracy_score(train_targets, train_preds)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_preds, val_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for (s11_val_data, val_labels), (tdr_val_data, _) in zip(s11_val_loader, TDR_val_loader):\n",
    "                # Move inputs and labels to the appropriate device\n",
    "                s11_val_data = s11_val_data.to(device)\n",
    "                tdr_val_data = tdr_val_data.to(device)\n",
    "                val_labels = val_labels.to(device)\n",
    "                \n",
    "                \n",
    "                outputs = model(s11_val_data.unsqueeze(-1), tdr_val_data.unsqueeze(-1))\n",
    "                loss = criterion(outputs, val_labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                val_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "                val_targets.extend(val_labels.cpu().numpy())\n",
    "\n",
    "        val_accuracy = accuracy_score(val_targets, val_preds)\n",
    "        \n",
    "        # Early stopping logic\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs. Best Val Loss: {best_val_loss:.4f}\")\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Train Accuracy: {train_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "            break\n",
    "            \n",
    "# Testing function\n",
    "def test_model(model):\n",
    "    model.eval()\n",
    "    test_preds, test_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for (s11_test_data, test_labels), (tdr_test_data, _) in zip(s11_test_loader, TDR_test_loader):\n",
    "            # Move inputs and labels to the appropriate device\n",
    "            s11_test_data = s11_test_data.to(device)\n",
    "            tdr_test_data = tdr_test_data.to(device)\n",
    "            test_labels = test_labels.to(device)\n",
    "            \n",
    "            outputs = model(s11_test_data.unsqueeze(-1), tdr_test_data.unsqueeze(-1))\n",
    "            test_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "            test_targets.extend(test_labels.cpu().numpy())\n",
    "\n",
    "    test_accuracy = accuracy_score(test_targets, test_preds)\n",
    "    test_conf_matrix = confusion_matrix(test_targets, test_preds)\n",
    "    classi_report = classification_report(test_targets, test_preds)\n",
    "    print(test_conf_matrix)\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix)\n",
    "    print('Test Accuracy - ',np.round(test_accuracy,3))\n",
    "    print('Classification Report')\n",
    "    print(classi_report)\n",
    "     \n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9ac9f14-6f1f-4643-bc9e-6aab81342afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "Multimodal_classifier = DutyClassifier(seq_len1=1003, seq_len2=1005, input_dim=1, num_classes=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(Multimodal_classifier.parameters(), lr=0.0001)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "Multimodal_classifier = Multimodal_classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e51c849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "1th Training Loop\n",
      "Early stopping triggered after 20 epochs. Best Val Loss: 3.9308\n",
      "Epoch 20/100, Train Accuracy: 0.4667, Val Accuracy: 0.6000\n",
      "[[3 4]\n",
      " [2 6]]\n",
      "Confusion Matrix\n",
      "<function confusion_matrix at 0x0000024A915831A0>\n",
      "Test Accuracy -  0.6\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.43      0.50         7\n",
      "           1       0.60      0.75      0.67         8\n",
      "\n",
      "    accuracy                           0.60        15\n",
      "   macro avg       0.60      0.59      0.58        15\n",
      "weighted avg       0.60      0.60      0.59        15\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "2th Training Loop\n",
      "Early stopping triggered after 28 epochs. Best Val Loss: 5.2025\n",
      "Epoch 28/100, Train Accuracy: 0.6889, Val Accuracy: 0.6000\n",
      "[[6 1]\n",
      " [4 4]]\n",
      "Confusion Matrix\n",
      "<function confusion_matrix at 0x0000024A915831A0>\n",
      "Test Accuracy -  0.667\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.86      0.71         7\n",
      "           1       0.80      0.50      0.62         8\n",
      "\n",
      "    accuracy                           0.67        15\n",
      "   macro avg       0.70      0.68      0.66        15\n",
      "weighted avg       0.71      0.67      0.66        15\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "3th Training Loop\n",
      "Early stopping triggered after 24 epochs. Best Val Loss: 8.6125\n",
      "Epoch 24/100, Train Accuracy: 0.6000, Val Accuracy: 0.6667\n",
      "[[0 7]\n",
      " [0 8]]\n",
      "Confusion Matrix\n",
      "<function confusion_matrix at 0x0000024A915831A0>\n",
      "Test Accuracy -  0.533\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.53      1.00      0.70         8\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.27      0.50      0.35        15\n",
      "weighted avg       0.28      0.53      0.37        15\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "4th Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 22 epochs. Best Val Loss: 7.7275\n",
      "Epoch 22/100, Train Accuracy: 0.6667, Val Accuracy: 0.6000\n",
      "[[6 1]\n",
      " [5 3]]\n",
      "Confusion Matrix\n",
      "<function confusion_matrix at 0x0000024A915831A0>\n",
      "Test Accuracy -  0.6\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.86      0.67         7\n",
      "           1       0.75      0.38      0.50         8\n",
      "\n",
      "    accuracy                           0.60        15\n",
      "   macro avg       0.65      0.62      0.58        15\n",
      "weighted avg       0.65      0.60      0.58        15\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "5th Training Loop\n",
      "Early stopping triggered after 60 epochs. Best Val Loss: 5.8943\n",
      "Epoch 60/100, Train Accuracy: 0.5111, Val Accuracy: 0.6667\n",
      "[[0 7]\n",
      " [0 8]]\n",
      "Confusion Matrix\n",
      "<function confusion_matrix at 0x0000024A915831A0>\n",
      "Test Accuracy -  0.533\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.53      1.00      0.70         8\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.27      0.50      0.35        15\n",
      "weighted avg       0.28      0.53      0.37        15\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "6th Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 28 epochs. Best Val Loss: 4.5777\n",
      "Epoch 28/100, Train Accuracy: 0.6000, Val Accuracy: 0.6000\n",
      "[[0 7]\n",
      " [0 8]]\n",
      "Confusion Matrix\n",
      "<function confusion_matrix at 0x0000024A915831A0>\n",
      "Test Accuracy -  0.533\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.53      1.00      0.70         8\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.27      0.50      0.35        15\n",
      "weighted avg       0.28      0.53      0.37        15\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "7th Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 17 epochs. Best Val Loss: 6.2699\n",
      "Epoch 17/100, Train Accuracy: 0.6889, Val Accuracy: 0.5333\n",
      "[[1 6]\n",
      " [1 7]]\n",
      "Confusion Matrix\n",
      "<function confusion_matrix at 0x0000024A915831A0>\n",
      "Test Accuracy -  0.533\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.14      0.22         7\n",
      "           1       0.54      0.88      0.67         8\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.52      0.51      0.44        15\n",
      "weighted avg       0.52      0.53      0.46        15\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "8th Training Loop\n",
      "Early stopping triggered after 26 epochs. Best Val Loss: 5.9423\n",
      "Epoch 26/100, Train Accuracy: 0.6667, Val Accuracy: 0.5333\n",
      "[[0 7]\n",
      " [0 8]]\n",
      "Confusion Matrix\n",
      "<function confusion_matrix at 0x0000024A915831A0>\n",
      "Test Accuracy -  0.533\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.53      1.00      0.70         8\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.27      0.50      0.35        15\n",
      "weighted avg       0.28      0.53      0.37        15\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "9th Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 45 epochs. Best Val Loss: 5.2191\n",
      "Epoch 45/100, Train Accuracy: 0.7111, Val Accuracy: 0.6000\n",
      "[[0 7]\n",
      " [0 8]]\n",
      "Confusion Matrix\n",
      "<function confusion_matrix at 0x0000024A915831A0>\n",
      "Test Accuracy -  0.533\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.53      1.00      0.70         8\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.27      0.50      0.35        15\n",
      "weighted avg       0.28      0.53      0.37        15\n",
      "\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "10th Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 16 epochs. Best Val Loss: 6.3390\n",
      "Epoch 16/100, Train Accuracy: 0.7333, Val Accuracy: 0.6667\n",
      "[[0 7]\n",
      " [0 8]]\n",
      "Confusion Matrix\n",
      "<function confusion_matrix at 0x0000024A915831A0>\n",
      "Test Accuracy -  0.533\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.53      1.00      0.70         8\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.27      0.50      0.35        15\n",
      "weighted avg       0.28      0.53      0.37        15\n",
      "\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "for i in range(1, 11):\n",
    "    print('-------------------------------------------------')\n",
    "    print(f'{i}th Training Loop')\n",
    "    s11_train_loader, s11_test_loader, s11_val_loader, TDR_train_loader, TDR_test_loader, TDR_val_loader = data_Scaling_Sync(s11_dataset, TDR_dataset, scaling_type='standard')\n",
    "    train_model(Multimodal_classifier, num_epochs=100, patience=15)\n",
    "    test_preds = test_model(Multimodal_classifier)\n",
    "    accuracy_list.append(test_preds)\n",
    "    \n",
    "    torch.save(Multimodal_classifier.state_dict(), rf'C:\\Master_thesis\\creating_dataset\\Model\\Multimodal_classifier_{i}.pth')\n",
    "    \n",
    "    print('-------------------------------------------------')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6680e537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6,\n",
       " 0.6666666666666666,\n",
       " 0.5333333333333333,\n",
       " 0.6,\n",
       " 0.5333333333333333,\n",
       " 0.5333333333333333,\n",
       " 0.5333333333333333,\n",
       " 0.5333333333333333,\n",
       " 0.5333333333333333,\n",
       " 0.5333333333333333]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9f65472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5599999999999999)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eaf2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f997666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
